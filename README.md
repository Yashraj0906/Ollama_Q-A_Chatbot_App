# üí¨ Enhanced Q&A Chatbot with Ollama

An intelligent **local chatbot** built using **Streamlit**, **LangChain**, and **Ollama**, capable of running open-source LLMs such as **Gemma**, **Phi-3**, and **Gemma-3:1B**.  
This app provides an easy-to-use interface for question answering with adjustable temperature and token settings ‚Äî **no API key required**!

---

## ‚ö° Features

‚úÖ **Interactive Chat UI** ‚Äî built with Streamlit  
‚úÖ **Runs Fully Offline** using Ollama models  
‚úÖ **Customizable Parameters** ‚Äî temperature and max tokens  
‚úÖ **LangChain-powered Prompt Management**  
‚úÖ **Beautiful Sidebar Controls**  
‚úÖ **Optional LangSmith Integration** for experiment tracking  

---

## ‚öôÔ∏è Setup Instructions
1Ô∏è‚É£ Clone the repository
git clone (https://github.com/Yashraj0906/Ollama_Q-A_Chatbot_App.git)
cd Ollama_Chatbot_App

2Ô∏è‚É£ Create a virtual environment
python -m venv .venv

Activate it:

Windows: .\.venv\Scripts\activate

macOS/Linux: source .venv/bin/activate

3Ô∏è‚É£ Install dependencies
pip install -r requirements.txt

4Ô∏è‚É£ Install and run Ollama

Download Ollama: https://ollama.com/download

Then pull your desired model:

ollama pull gemma2
# or
ollama pull phi3
# or
ollama pull gemma3:1b


Verify installation:

ollama list

5Ô∏è‚É£ Run the app
streamlit run app.py
